{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Credit to GitHub user Jaimin09\n",
    "Link: https://github.com/Jaimin09/Coding-Lane-Assets/tree/main/Logistic%20Regression%20in%20Python%20from%20Scratch\n",
    "Last accessed: 28/10/2021\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# ! Set seed and seed calling function\n",
    "rng = np.random.default_rng(1)\n",
    "\n",
    "# ! Get dataset\n",
    "filepath = 'dec_sep_MPHWA.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df= df.reset_index()\n",
    "\n",
    "dec_path = 'dec_MPHWA.csv'\n",
    "dec_df = pd.read_csv(dec_path)\n",
    "dec_df = dec_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reshape(X, Y):\n",
    "    # Drop id column from dataframes\n",
    "    X = X.drop(\"ID\", axis = 1)\n",
    "    Y = Y.drop(\"ID\", axis = 1)\n",
    "    \n",
    "    # Define dataframes as variables\n",
    "    X = X.values\n",
    "    Y = Y.values\n",
    "    \n",
    "    # Reshape dataframes to appropriate shape\n",
    "    X = X.T\n",
    "    Y = Y.reshape(1, X.shape[1])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even out the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvenDF(df):\n",
    "    # Split dataframe into won a medal and didnt win a medal\n",
    "    df_1 = df[df.MedalEarned == 1]\n",
    "    df_0 = df[df.MedalEarned == 0]\n",
    "    \n",
    "    # Randomly sample df_0 to size of df_1\n",
    "    df_0 = df_0.sample(n = len(df_1), random_state=rng.integers(100000))\n",
    "    \n",
    "    return df_1, df_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestSampler(df, X_list, Y_list):\n",
    "    # Split dataframe into won a medal and didnt win a medal\n",
    "    df_1 = df[df.MedalEarned == 1]\n",
    "    df_0 = df[df.MedalEarned == 0]\n",
    "    \n",
    "    # Randomly sample test df_1 and df_0\n",
    "    df_1_test = df_1.sample(n = 100, random_state=rng.integers(100000))\n",
    "    df_0_test = df_0.sample(n = 100, random_state=rng.integers(100000))\n",
    "    \n",
    "    # Remove test samples from df_1 and df_0\n",
    "    df = df.drop(df_1_test.index)\n",
    "    df_testless = df.drop(df_0_test.index)\n",
    "    \n",
    "    # Concat df_1_test and df_0_test\n",
    "    df_test_list = [df_1_test, df_0_test]\n",
    "    df_test = pd.concat(df_test_list)\n",
    "    \n",
    "    # Reduce and split X and Y dataframes\n",
    "    X_test = df_test[X_list]\n",
    "    Y_test = df_test[Y_list]\n",
    "    \n",
    "    return df_testless, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainValidate(df, X_list, Y_list):\n",
    "    # Randomly sample df_0 to size of df_1\n",
    "    df_1, df_0 = EvenDF(df)\n",
    "    \n",
    "    # Randomly sample validate df_1 and df_0\n",
    "    df_1_validate = df_1.sample(frac= 0.2, random_state=rng.integers(100000))\n",
    "    df_0_validate = df_0.sample(frac= 0.2, random_state=rng.integers(100000))\n",
    "    \n",
    "    # Remove validation samples from df_1 and df_0\n",
    "    # The rest of df_1 and df_0 are training\n",
    "    df_1_train = df_1.drop(df_1_validate.index)\n",
    "    df_0_train = df_0.drop(df_0_validate.index)\n",
    "    \n",
    "    # concatinate training and validation\n",
    "    df_validate_list = [df_1_validate, df_0_validate]\n",
    "    df_train_list =    [df_1_train, df_0_train]\n",
    "    \n",
    "    df_validate = pd.concat(df_validate_list)\n",
    "    df_train =    pd.concat(df_train_list)\n",
    "    \n",
    "    # Reduce and split X and Y dataframes\n",
    "    X_validate = df_validate[X_list]\n",
    "    Y_validate = df_validate[Y_list]\n",
    "    X_train =    df_train[X_list]\n",
    "    Y_train =    df_train[Y_list]\n",
    "    \n",
    "    return X_train, Y_train, X_validate, Y_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(X, Y, l_rate, iterations):\n",
    "    m = X.shape[1] # Observations\n",
    "    n = X.shape[0] # Types of parameters\n",
    "    \n",
    "    W = np.zeros((n,1)) # All a parameters\n",
    "    B = 0\n",
    "    \n",
    "    cost_list = [] # Empty cost list\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        lin_func = np.dot(W.T, X) + B # Linear function\n",
    "        sf = Sigmoid(lin_func) # Sigmoid function\n",
    "        \n",
    "        # Cost function\n",
    "        cost = -(1/m)*np.sum( Y*np.log(sf) + (1-Y)*np.log(1-sf))\n",
    "        \n",
    "        # Gradient Descent\n",
    "        dW = (1/m)*np.dot(sf-Y, X.T)\n",
    "        dB = (1/m)*np.sum(sf - Y)\n",
    "        \n",
    "        W = W - l_rate * dW.T\n",
    "        B = B - l_rate * dB\n",
    "        \n",
    "        # Keeping track of our cost function value\n",
    "        cost_list.append(cost)\n",
    "    \n",
    "    return W, B, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunModel(df_testless, iterations, l_rate):\n",
    "    # Make X_train, Y_train, X_validate, Y_validate\n",
    "    X_train, Y_train, X_validate, Y_validate = TrainValidate(df_testless, X_list, Y_list)\n",
    "    \n",
    "    # Import and reshape training and validation dataframes\n",
    "    X_train, Y_train = Reshape(X_train, Y_train)\n",
    "    X_validate, Y_validate = Reshape(X_validate, Y_validate)\n",
    "    \n",
    "    # Call Model function\n",
    "    W, B, cost_list = Model(X_train, Y_train, l_rate, iterations)\n",
    "    \n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple runs of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = ['ID', \n",
    "        'PreviousMedals', \n",
    "        'Height_div_avg', \n",
    "        'Weight_div_avg', \n",
    "        'Age_div_avg'\n",
    "        ]\n",
    "\n",
    "Y_list = ['ID', 'MedalEarned']\n",
    "\n",
    "def RunMore(times, iterations, l_rate):\n",
    "    W_list = []\n",
    "    B_list = []\n",
    "    \n",
    "    # Create test sample\n",
    "    df_testless, X_test, Y_test = TestSampler(df, X_list, Y_list)\n",
    "    \n",
    "    for i in range(times):\n",
    "        # Run model\n",
    "        W, B = RunModel(df_testless, iterations, l_rate)\n",
    "        \n",
    "        # Append parameters, accuracy and occurances to lists\n",
    "        W_list.append(W)\n",
    "        B_list.append(B)\n",
    "        \n",
    "        # Progress bar\n",
    "        if len(W_list) % 10 == 0:\n",
    "            print(f'{times - len(W_list)} runs left.')\n",
    "    \n",
    "    return W_list, B_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classify(X, W, B, cop):\n",
    "    lin_func = np.dot(W.T, X) + B # Linear function\n",
    "    sf = Sigmoid(lin_func) # Sigmoid function\n",
    "    \n",
    "    # Make sf binary array with data type int64\n",
    "    sf = sf > cop # Sets sf to one if > 0 or 0 if < 0\n",
    "    sf = np.array(sf, dtype = 'int64')\n",
    "    \n",
    "    return sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(sf, Y):\n",
    "    # 1 = True Pos, 0 = True Neg, -1 = False Neg, 2 = False Pos \n",
    "    guesses = sf * 2 - Y\n",
    "    occurance = [[x, list(guesses[0]).count(x)] for x in set(list(guesses[0]))]\n",
    "    occ_d = {1:0, 0:0, -1:0, 2:0}\n",
    "    \n",
    "    # Assign value to keys e.g. TP : 22\n",
    "    for i in occurance: \n",
    "        occ_d[i[0]] = i[1]\n",
    "    \n",
    "    # True Positive, True Negative, False Positive and False Negative\n",
    "    tp, tn, fp, fn = occ_d[1], occ_d[0], occ_d[2], occ_d[-1]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    return acc, occ_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decathlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decathlon(df, W_list, B_list, cop):\n",
    "    dec_acc_list = []\n",
    "    dec_occ_list = []\n",
    "    \n",
    "    # Reduce and split X and Y dataframes\n",
    "    X_dec = df[X_list]\n",
    "    Y_dec = df[Y_list]\n",
    "    \n",
    "    # Import and reshape dec data\n",
    "    X_dec, Y_dec = Reshape(X_dec, Y_dec)\n",
    "    \n",
    "    # Test parameters on dec\n",
    "    for i in range(len(W_list)):\n",
    "        sf = Classify(X_dec, W_list[i], B_list[i], cop)\n",
    "        da, dod = Accuracy(sf, Y_dec)\n",
    "        dec_acc_list.append(da)\n",
    "        dec_occ_list.append(dod)\n",
    "    \n",
    "    return dec_acc_list, dec_occ_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 runs left.\n",
      "30 runs left.\n",
      "20 runs left.\n",
      "10 runs left.\n",
      "0 runs left.\n"
     ]
    }
   ],
   "source": [
    "W_list, B_list = RunMore(times= 50, iterations= 5000, l_rate= 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do liste\n",
    "normalitetstest færdig for en gang \n",
    "f-test færdig for en en gang \n",
    "generaliser til en funktion, som kan gøre det for de parametre, der giver den højeste accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45004836 0.42380058 0.50624631 ... 0.39831545 0.49010789 0.30849168]]\n",
      "2696.3260216256813\n",
      "[[0.38683482 0.4014885  0.41200644 ... 0.41291475 0.41343343 0.41535865]]\n",
      "2675.654977008481\n"
     ]
    }
   ],
   "source": [
    "# Classify til f_test \n",
    "def Classify_f(df, W, B):\n",
    "    \n",
    "    # Få data til model \n",
    "    X_dims = df[X_list] \n",
    "    Y_dims = df[Y_list]\n",
    "    X_dims, Y_dims = Reshape(X_dims, Y_dims)\n",
    "    \n",
    "    # Få modelgæt\n",
    "    lin_func = np.dot(W.T, X_dims) + B # Linear function\n",
    "    sf = Sigmoid(lin_func) # Sigmoid function\n",
    "    \n",
    "    return sf\n",
    "\n",
    "# Få liste af modelgæt, når w er udændret\n",
    "sig_0 = Classify_f(df, W_list[0], B_list[0])\n",
    "print(sig_0)\n",
    "sig_0_sum = np.sum(sig_0)\n",
    "print(sig_0_sum)\n",
    "\n",
    "# Få liste af modelgæt, når w_i = 0 er udændret\n",
    "\n",
    "# Lav en kopi af modelvægte, og sæt den første til 0\n",
    "W1_list = copy.deepcopy(W_list)\n",
    "W1_list[0][0] = 0 \n",
    "\n",
    "sig_1 = Classify_f(df, W1_list[0], B_list[0])\n",
    "print(sig_1)\n",
    "sig_1_sum = np.sum(sig_1)\n",
    "print(sig_1_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 6153",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7428/4264171295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshapiro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'norm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36mprobplot\u001b[1;34m(x, sparams, dist, fit, plot, rvalue)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;31m# perform a linear least squares fit.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mslope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinregress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mosm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mosr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mplot\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_mstats_common.py\u001b[0m in \u001b[0;36mlinregress\u001b[1;34m(x, y, alternative)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;31m#   ssxm = mean( (x-mean(x))^2 )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;31m#   ssxym = mean( (x-mean(x)) * (y-mean(y)) )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0mssxm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssxym\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssym\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;31m# R-value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcov\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcov\u001b[1;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrowvar\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2427\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2428\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2430\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mddof\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 6153"
     ]
    }
   ],
   "source": [
    "x = scipy.stats.shapiro(sig_0)\n",
    "q = scipy.stats.probplot(sig_0, dist = 'norm', plot = plt)\n",
    "plt.show(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapiroResult(statistic=0.9497095346450806, pvalue=1.2914366647217514e-41)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
