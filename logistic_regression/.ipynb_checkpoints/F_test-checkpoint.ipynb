{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Credit to GitHub user Jaimin09\n",
    "Link: https://github.com/Jaimin09/Coding-Lane-Assets/tree/main/Logistic%20Regression%20in%20Python%20from%20Scratch\n",
    "Last accessed: 28/10/2021\n",
    "'''\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import portablelogresmodel as model\n",
    "import scipy\n",
    "\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and set seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! Get dataset\n",
    "filepath = 'Datasets\\dec_sep_MPHWA.csv' # Data for Specialized athletes i.e. competing in one sport\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.reset_index() # Resets index for dataset \n",
    "\n",
    "dec_path = 'Datasets\\dec_MPHWA.csv' # Data for decathlon athletes \n",
    "dec_df = pd.read_csv(dec_path)\n",
    "dec_df = dec_df.reset_index() # Resets index for dataset \n",
    "\n",
    "# ! Set seed and seed calling function\n",
    "rng = np.random.default_rng(1) \n",
    "\n",
    "# List of variables we are interested in \n",
    "X_list = ['ID',  \n",
    "        'PreviousMedals',\n",
    "        'Height_div_avg', \n",
    "        'Weight_div_avg', \n",
    "        'Age_div_avg'\n",
    "        ]\n",
    "\n",
    "# Change X_list to exclude ID \n",
    "# X_list = X_list[1:]\n",
    "\n",
    "# List containing medals earned for each athlete  \n",
    "Y_list = ['ID', 'MedalEarned']\n",
    "\n",
    "# Import model weights after portableregressionmodel.py has been run \n",
    "W_array = np.genfromtxt('Parameters/W.csv', delimiter=',')# Len of array is equal to the number of iterations of the model\n",
    "B_array = np.genfromtxt('Parameters/B.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce weight for model\n",
    "def ProduceWeights(df, W, B):\n",
    "\n",
    "    # Get data for model\n",
    "    X_model_df = df[X_list] # Dataframe contains X_list columns \n",
    "    Y_model_df = df[Y_list]\n",
    "\n",
    "    X_array, Y_array = model.Reshape(X_model_df, Y_model_df) # Drops ID and transforms each column to a numpy array\n",
    "\n",
    "    # Get model guesses \n",
    "    \n",
    "    # Use dot product on the four weights and the variable values for each athlete i.e. Ath1 = w1*var1 + w2*var2(..) + B\n",
    "    lin_func = np.dot(W.T, X_array) + B\n",
    "    \n",
    "    # Use linear expression in sigmoid function to get model guess for each athlete \n",
    "    sf = model.Sigmoid(lin_func) \n",
    "    \n",
    "    return sf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate model predictions in two cases. \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "# Append model guesses to lists dependent on  the number of variables i.e. 4 variables creates a list of 4 arrays. \n",
    "\n",
    "def f_test_loop(W, B):\n",
    "    \n",
    "    # Store model guesses with weights unchanged, and create empty list to store model prediction with weights changed\n",
    "   \n",
    "    sig_0 = ProduceWeights(df, W, B)\n",
    "    sig_1_store = []  \n",
    "    \n",
    "    # Exclude ID column from loop\n",
    "    drop_ID = X_list[1:]\n",
    "    \n",
    "    for index,element in enumerate(drop_ID):\n",
    "        \n",
    "        # Print output for each iteration\n",
    "        print(f'The current index is {index}')\n",
    "        print(f'The current element is {element}')\n",
    "        \n",
    "        # Change weights back to values found in W\n",
    "        W1 = copy.deepcopy(W)\n",
    "        \n",
    "        W1[index] = 0 # index weight set to 0\n",
    "        \n",
    "        # Get a list of model guesses where weights are changed\n",
    "        sig_1 = ProduceWeights(df, W1, B)\n",
    "        print(sig_1)\n",
    "        \n",
    "        # Append array of model guesses to list \n",
    "        sig_1_store.append(sig_1)\n",
    "    \n",
    "    return sig_0, sig_1_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call F_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current index is 0\n",
      "The current element is PreviousMedals\n",
      "[0.92524216 0.20173657 0.43566097 ... 0.55253714 0.37581016 0.29995489]\n",
      "The current index is 1\n",
      "The current element is Height_div_avg\n",
      "[0.92213526 0.19923577 0.41987367 ... 0.55507281 0.36356257 0.31676768]\n",
      "The current index is 2\n",
      "The current element is Weight_div_avg\n",
      "[0.32566492 0.33365407 0.46003613 ... 0.46465944 0.4624237  0.44020105]\n",
      "The current index is 3\n",
      "The current element is Age_div_avg\n",
      "[0.94741978 0.25644853 0.39402305 ... 0.48648425 0.33168873 0.25306099]\n"
     ]
    }
   ],
   "source": [
    "# Get first weight in CSV file of weights \n",
    "W_par = np.array([W_array[0][0], W_array[1][0], W_array[2][0], W_array[3][0]], ndmin= 0)\n",
    "B_par = B_array[0]\n",
    "\n",
    "# Create list of arrays of model guesses \n",
    "p_vector_0, p_vector_1 = f_test_loop(W_par,B_par) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The current variable is: PreviousMedals, sig_1_norm is currently:ShapiroResult(statistic=0.8800283074378967, pvalue=0.0)\n",
      " The current variable is: Height_div_avg, sig_1_norm is currently:ShapiroResult(statistic=0.8890291452407837, pvalue=0.0)\n",
      " The current variable is: Weight_div_avg, sig_1_norm is currently:ShapiroResult(statistic=0.8226956129074097, pvalue=0.0)\n",
      " The current variable is: Age_div_avg, sig_1_norm is currently:ShapiroResult(statistic=0.8803070187568665, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Test each array in sig0_store and sig1_store for normality \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "# Append result to list \n",
    "\n",
    "def normality_loop(sig_0_probabilities, sig_1_probabilities):\n",
    "    \n",
    "    # Store normality test for model guesses with weights unchanged, i.e. sig_0\n",
    "    sig_0_norm =  scipy.stats.shapiro(sig_0_probabilities)\n",
    "    # Create lists to store result of normality test \n",
    "    sig_1_norm = []\n",
    "    \n",
    "    # Ã†NDR TIL AT SMIDE UD AF X-listen!\n",
    "    drop_ID = X_list[1:] # Only used for print statement \n",
    "    \n",
    "    # Normality test is done for each array in the two lists of model guesses \n",
    "    for i in range(len(sig_1_probabilities)): # Ensure \n",
    "        sig_1_norm.append(scipy.stats.shapiro(sig_1_probabilities[i]))\n",
    "        print(f' The current variable is: {drop_ID[i]}, sig_1_norm is currently:{sig_1_norm[i]}')\n",
    "        \n",
    "    return sig_0_norm,sig_1_norm\n",
    "\n",
    "# Store normality test result for each array of weights\n",
    "shapiro_0, shapiro_1 = normality_loop(p_vector_0, p_vector_1)\n",
    "\n",
    "\n",
    "### THIS IS ADDTIONAL CODE TO PLOT A QQPLOT - DELETE IF NON-FUNCTIONAL BY CLOSE TO DEADLINE\n",
    "#z = scipy.stats.probplot(df_sig_0[\"Prob\"], dist = 'norm', plot = plt)\n",
    "#q = scipy.stats.probplot(df_sig_1[\"Prob\"], dist = 'norm', plot = plt)\n",
    "\n",
    "#plt.show(z)\n",
    "#plt.show(q)\n",
    "\n",
    "# Test for normality showed that including previous medals, caused the distribution to be non-normal. PreviousMedals is therefore excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current variable is: PreviousMedals \n",
      " The current p-value is: 5.223256799169462e-05\n",
      " null hypothesis is rejected: p-value = 5.223256799169462e-05. The probablity of the two distributions' variance being equal is low. The variable is likely to impact model output\n",
      "The current variable is: Height_div_avg \n",
      " The current p-value is: 0.02825330415181948\n",
      " null hypothesis is rejected: p-value = 0.02825330415181948. The probablity of the two distributions' variance being equal is low. The variable is likely to impact model output\n",
      "The current variable is: Weight_div_avg \n",
      " The current p-value is: 1.1102230246251565e-16\n",
      " null hypothesis is rejected: p-value = 1.1102230246251565e-16. The probablity of the two distributions' variance being equal is low. The variable is likely to impact model output\n",
      "The current variable is: Age_div_avg \n",
      " The current p-value is: 0.9737840882713829\n",
      "null hypothesis cannot be rejected: p-value = 0.9737840882713829. The probablity of the two distributions' variance being equal is high. The variable is unlikely to impact model output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.223256799169462e-05,\n",
       " 0.02825330415181948,\n",
       " 1.1102230246251565e-16,\n",
       " 0.9737840882713829]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F-test: https://link.springer.com/book/10.1007%2F978-3-319-46162-5 \n",
    "# Code adapted from: https://www.statology.org/f-test-python/\n",
    "\n",
    "# F test arrays of model guesses \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "\n",
    "def f_test(sig_0_probabilities,sig_1_probabilities):\n",
    "    f_test_list = []\n",
    "    \n",
    "    drop_ID = X_list[1:]\n",
    "    \n",
    "    for i in range(len(sig_1_probabilities)):\n",
    "        f = np.var(sig_0_probabilities, ddof=1)/np.var(sig_1_probabilities[i], ddof=1) #calculate F test statistic \n",
    "        dfn = sig_0_probabilities.size-1 #define degrees of freedom numerator \n",
    "        dfd = sig_1_probabilities[i].size-1 #define degrees of freedom denominator \n",
    "        p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic\n",
    "        f_test_list.append(p)\n",
    "        \n",
    "        # Print current variable and p value \n",
    "        print(f'The current variable is: {drop_ID[i]} \\n The current p-value is: {p}')\n",
    "        \n",
    "        # Define alpha and print conclusion of hypothesis test \n",
    "        if p <= 0.05:\n",
    "            print(f\" null hypothesis is rejected: p-value = {p}. The probablity of the two distributions' variance being equal is low. The variable is likely to impact model output\")\n",
    "        else:\n",
    "            print(f\"null hypothesis cannot be rejected: p-value = {p}. The probablity of the two distributions' variance being equal is high. The variable is unlikely to impact model output.\") \n",
    "    \n",
    "    return f_test_list\n",
    "\n",
    "f_test(p_vector_0, p_vector_1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
