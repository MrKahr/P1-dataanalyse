{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Credit to GitHub user Jaimin09\n",
    "Link: https://github.com/Jaimin09/Coding-Lane-Assets/tree/main/Logistic%20Regression%20in%20Python%20from%20Scratch\n",
    "Last accessed: 28/10/2021\n",
    "'''\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import portablelogresmodel as model\n",
    "import scipy\n",
    "\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and set seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ! Get dataset\n",
    "filepath = 'Datasets\\dec_sep_MPHWA.csv' # Data for Specialized athletes i.e. competing in one sport\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.reset_index() # Resets index for dataset \n",
    "\n",
    "dec_path = 'Datasets\\dec_MPHWA.csv' # Data for decathlon athletes \n",
    "dec_df = pd.read_csv(dec_path)\n",
    "dec_df = dec_df.reset_index() # Resets index for dataset \n",
    "\n",
    "# ! Set seed and seed calling function\n",
    "rng = np.random.default_rng(1) \n",
    "\n",
    "# List of variables we are interested in \n",
    "X_list = ['ID',  \n",
    "        'PreviousMedals',\n",
    "        'Height_div_avg', \n",
    "        'Weight_div_avg', \n",
    "        'Age_div_avg'\n",
    "        ]\n",
    "\n",
    "# List containing medals earned for each athlete  \n",
    "Y_list = ['ID', 'MedalEarned']\n",
    "\n",
    "# Import model weights after portableregressionmodel.py has been run \n",
    "W_array = np.genfromtxt('Parameters/W.csv', delimiter=',')# Len of array is equal to the number of iterations of the model\n",
    "B_array = np.genfromtxt('Parameters/B.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce weight for model\n",
    "def ProduceWeights(df, W, B):\n",
    "\n",
    "    # Get data for model\n",
    "    X_model_df = df[X_list] # Dataframe contains X_list columns \n",
    "    Y_model_df = df[Y_list]\n",
    "\n",
    "    X_array, Y_array = model.Reshape(X_model_df, Y_model_df) # Drops ID and transforms each column to a numpy array\n",
    "\n",
    "    # Get model guesses \n",
    "    \n",
    "    # Use dot product on the four weights and the variable values for each athlete i.e. Ath1 = w1*var1 + w2*var2(..) + B\n",
    "    lin_func = np.dot(W.T, X_array) + B\n",
    "    \n",
    "    # Use linear expression in sigmoid function to get model guess for each athlete \n",
    "    sf = model.Sigmoid(lin_func) \n",
    "    \n",
    "    return sf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate model predictions in two cases. \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "# Append model guesses to lists dependent on  the number of variables i.e. 4 variables creates a list of 4 arrays. \n",
    "\n",
    "def f_test_loop(W, B):\n",
    "    \n",
    "    # Create list to store model predictions in two cases\n",
    "    ### DEFINE SIG0 BEFORE LOOP + CHANGE VARIABLE NAMES\n",
    "    sig_0_store = [] \n",
    "    sig_1_store = []  \n",
    "    drop_ID = X_list[1:]\n",
    "    \n",
    "    for index,element in enumerate(drop_ID):\n",
    "        \n",
    "        # Print output for each iteration\n",
    "        print(f'The current index is {index}')\n",
    "        print(f'The current element is {element}')\n",
    "        \n",
    "        # Change weights back to values found in W\n",
    "        W1 = copy.deepcopy(W)\n",
    "        \n",
    "        W1[index] = 0 # index weight set to 0\n",
    "        \n",
    "        # Get list of model guesses with unchanged weights \n",
    "        sig_0 = ProduceWeights(df, W, B)\n",
    "        print(sig_0)\n",
    "        \n",
    "        # Get a list of model guesses where weights are changed\n",
    "        sig_1 = ProduceWeights(df, W1, B)\n",
    "        print(sig_1)\n",
    "        \n",
    "        # Append array of model guesses to list \n",
    "        sig_0_store.append(sig_0)\n",
    "        sig_1_store.append(sig_1)\n",
    "    \n",
    "    return sig_0_store, sig_1_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call F_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vores i er 0\n",
      "vores element er PreviousMedals\n",
      "vores len er 4\n",
      "[0.92524216 0.20173657 0.43566097 ... 0.55253714 0.37581016 0.29995489]\n",
      "[0.92524216 0.20173657 0.43566097 ... 0.55253714 0.37581016 0.29995489]\n",
      "vores i er 1\n",
      "vores element er Height_div_avg\n",
      "vores len er 4\n",
      "[0.92524216 0.20173657 0.43566097 ... 0.55253714 0.37581016 0.29995489]\n",
      "[0.92213526 0.19923577 0.41987367 ... 0.55507281 0.36356257 0.31676768]\n",
      "vores i er 2\n",
      "vores element er Weight_div_avg\n",
      "vores len er 4\n",
      "[0.92524216 0.20173657 0.43566097 ... 0.55253714 0.37581016 0.29995489]\n",
      "[0.32566492 0.33365407 0.46003613 ... 0.46465944 0.4624237  0.44020105]\n",
      "vores i er 3\n",
      "vores element er Age_div_avg\n",
      "vores len er 4\n",
      "[0.92524216 0.20173657 0.43566097 ... 0.55253714 0.37581016 0.29995489]\n",
      "[0.94741978 0.25644853 0.39402305 ... 0.48648425 0.33168873 0.25306099]\n"
     ]
    }
   ],
   "source": [
    "# Get first weight in CSV file of weights \n",
    "W_par = np.array([W_array[0][0], W_array[1][0], W_array[2][0], W_array[3][0]], ndmin= 0)\n",
    "B_par = B_array[0]\n",
    "\n",
    "# Create list of arrays of model guesses \n",
    "p_vector_0, p_vector_1 = f_test_loop(W_par,B_par) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " vores variabel er: PreviousMedals \n",
      " vores x_norm er ShapiroResult(statistic=0.8946238160133362, pvalue=0.0), \n",
      " vores y_norm er ShapiroResult(statistic=0.8800283074378967, pvalue=0.0)\n",
      " vores variabel er: Height_div_avg \n",
      " vores x_norm er ShapiroResult(statistic=0.8946238160133362, pvalue=0.0), \n",
      " vores y_norm er ShapiroResult(statistic=0.8890291452407837, pvalue=0.0)\n",
      " vores variabel er: Weight_div_avg \n",
      " vores x_norm er ShapiroResult(statistic=0.8946238160133362, pvalue=0.0), \n",
      " vores y_norm er ShapiroResult(statistic=0.8226956129074097, pvalue=0.0)\n",
      " vores variabel er: Age_div_avg \n",
      " vores x_norm er ShapiroResult(statistic=0.8946238160133362, pvalue=0.0), \n",
      " vores y_norm er ShapiroResult(statistic=0.8803070187568665, pvalue=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdsan\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:1760: UserWarning: p-value may not be accurate for N > 5000.\n",
      "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
     ]
    }
   ],
   "source": [
    "# Test each array in sig0_store and sig1_store for normality \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "# Append result to list \n",
    "\n",
    "def normality_loop(sig_0_probabilities, sig_1_probabilities):\n",
    "    \n",
    "    # Create lists to store result of normality test \n",
    "    x_norm = [] ### CHANGE VARIABLE NAMES \n",
    "    y_norm = []\n",
    "    drop_ID = X_list[1:] # Only used for print statement \n",
    "    \n",
    "    # Normality test is done for each array in the two lists of model guesses \n",
    "    for i in range(len(sig_0_probabilities)): # Ensure \n",
    "        x_norm.append(scipy.stats.shapiro(sig_0_probabilities[i])) ### CREATES TOO MANY TESTS, WE JUST NEED 1\n",
    "        y_norm.append(scipy.stats.shapiro(sig_1_probabilities[i]))\n",
    "        print(f' vores variabel er: {drop_ID[i]} \\n vores x_norm er {x_norm[i]}, \\n vores y_norm er {y_norm[i]}')\n",
    "        \n",
    "    return x_norm,y_norm\n",
    "\n",
    "shapiro_0, shapiro_1 = normality_loop(p_vector_0, p_vector_1)\n",
    "\n",
    "\n",
    "\n",
    "#z = scipy.stats.probplot(df_sig_0[\"Prob\"], dist = 'norm', plot = plt)\n",
    "#q = scipy.stats.probplot(df_sig_1[\"Prob\"], dist = 'norm', plot = plt)\n",
    "\n",
    "#plt.show(z)\n",
    "#plt.show(q)\n",
    "\n",
    "# Test for normality showed that including previous medals, caused the distribution to be non-normal. PreviousMedals is therefore excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vores variabel er PreviousMedals \n",
      " vores p er 5.223256799169462e-05\n",
      "nulhypotesen forkastes da p-værdien = 5.223256799169462e-05. Dermed er sandsynligheden for at de to fordelinger har samme varians lav. Variablen har stor betydning for modellens output.\n",
      "vores variabel er Height_div_avg \n",
      " vores p er 0.02825330415181948\n",
      "nulhypotesen forkastes da p-værdien = 0.02825330415181948. Dermed er sandsynligheden for at de to fordelinger har samme varians lav. Variablen har stor betydning for modellens output.\n",
      "vores variabel er Weight_div_avg \n",
      " vores p er 1.1102230246251565e-16\n",
      "nulhypotesen forkastes da p-værdien = 1.1102230246251565e-16. Dermed er sandsynligheden for at de to fordelinger har samme varians lav. Variablen har stor betydning for modellens output.\n",
      "vores variabel er Age_div_avg \n",
      " vores p er 0.9737840882713829\n",
      "nulhypotesen kan ikke forkastes da p-værdien = 0.9737840882713829. Dermed er der høj sandsynlighed for at de to fordelinger har samme varians. Variablen kan have stor betydning for modellens output.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.223256799169462e-05,\n",
       " 0.02825330415181948,\n",
       " 1.1102230246251565e-16,\n",
       " 0.9737840882713829]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F-test: https://link.springer.com/book/10.1007%2F978-3-319-46162-5 \n",
    "# Code adapted from: https://www.statology.org/f-test-python/\n",
    "\n",
    "# F test arrays of model guesses \n",
    "# 0. Model weights remain unchanged \n",
    "# 1. ith weight is set to 0\n",
    "\n",
    "def f_test(sig_0_probabilities,sig_1_probabilities):\n",
    "    f_test_list = []\n",
    "    drop_ID = X_list[1:]\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        f = np.var(sig_0_probabilities[i], ddof=1)/np.var(sig_1_probabilities[i], ddof=1) #calculate F test statistic \n",
    "        dfn = sig_0_probabilities[i].size-1 #define degrees of freedom numerator \n",
    "        dfd = sig_1_probabilities[i].size-1 #define degrees of freedom denominator \n",
    "        p = 1-scipy.stats.f.cdf(f, dfn, dfd) #find p-value of F test statistic\n",
    "        f_test_list.append(p)\n",
    "        \n",
    "        # Print current variable and p value \n",
    "        print(f'vores variabel er {drop_ID[i]} \\n vores p er {p}')\n",
    "        \n",
    "        # Define alpha and print conclusion of hypothesis test \n",
    "        if p <= 0.05:\n",
    "            print(f'nulhypotesen forkastes da p-værdien = {p}. Dermed er sandsynligheden for at de to fordelinger har samme varians lav. Variablen har stor betydning for modellens output.')\n",
    "        else:\n",
    "            print(f'nulhypotesen kan ikke forkastes da p-værdien = {p}. Dermed er der høj sandsynlighed for at de to fordelinger har samme varians. Variablen kan have stor betydning for modellens output.')\n",
    "    \n",
    "    return f_test_list\n",
    "\n",
    "f_test(p_vector_0, p_vector_1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
